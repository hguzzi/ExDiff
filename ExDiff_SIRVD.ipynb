{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 3774,
     "status": "ok",
     "timestamp": 1753173814640,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "UXY0F6Ig53HP",
    "outputId": "1d4fc5be-6a54-4a36-fe84-85266b287efa"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "#@title Drive Mount { display-mode: \"form\" }\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount = True)\n",
    "\n",
    "\n",
    "# Hide the code\n",
    "display(HTML('''\n",
    "<script>\n",
    "var cell = document.querySelector('.input');\n",
    "if (cell) cell.style.display = 'none';\n",
    "</script>\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fP7KNNkVTf5O"
   },
   "outputs": [],
   "source": [
    "#@title Main folder { display-mode: \"form\" }\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/ExDiff/SIRVD_folder/folder\" #@param {type:\"string\"}\n",
    "#@markdown Set main folder in which save files\n",
    "\n",
    "%cd $save_path\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "sep = os.sep\n",
    "\n",
    "\n",
    "# Hide the code\n",
    "display(HTML('''\n",
    "<script>\n",
    "var cell = document.querySelector('.input');\n",
    "if (cell) cell.style.display = 'none';\n",
    "</script>\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1753173857324,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "sGOSpfNZIYX-",
    "outputId": "bcba9226-fdb7-44ae-a8b4-261f5980d837"
   },
   "outputs": [],
   "source": [
    "#@title Select Graph Model Type { display-mode: \"form\" }\n",
    "model_type = \"Barabasi-Albert\" #@param [\"Erdos-Renyi\", \"Stochastic Block Model\", \"Random Geometric\", \"Barabasi-Albert\", \"Watts-Strogatz\"]\n",
    "\n",
    "\n",
    "net = 'ER'\n",
    "if model_type == 'Stochastic Block Model':\n",
    "   net = 'SBM'\n",
    "elif model_type == 'Barabasi-Albert':\n",
    "   net = 'BA'\n",
    "elif model_type == 'Random Geometric':\n",
    "   net = 'RG'\n",
    "elif model_type == 'Watts-Strogatz':\n",
    "   net = 'WS'\n",
    "\n",
    "# Hide the code\n",
    "display(HTML('''\n",
    "<script>\n",
    "var cell = document.querySelector('.input');\n",
    "if (cell) cell.style.display = 'none';\n",
    "</script>\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 870
    },
    "executionInfo": {
     "elapsed": 1152,
     "status": "ok",
     "timestamp": 1753173870439,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "0KhxWqfqIajq",
    "outputId": "7a7fa9a7-72e0-43f0-c119-9696b6b590bf"
   },
   "outputs": [],
   "source": [
    "#@title Configure and Generate Graph { display-mode: \"form\" }\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Access model_type from previous cell\n",
    "selected_model = model_type\n",
    "\n",
    "#@markdown ## Common Parameters\n",
    "num_nodes = 300 #@param {type:\"slider\", min:10, max:10000, step:10}\n",
    "seed = 42 #@param {type:\"integer\"}\n",
    "show_labels = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ## Erdös-Rényi Parameters\n",
    "probability = 0.1 #@param {type:\"slider\", min:0.01, max:1.0, step:0.01}\n",
    "directed = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ## Stochastic Block Model Parameters\n",
    "num_communities = 3 #@param {type:\"slider\", min:2, max:6, step:1}\n",
    "community_sizes = \"200, 100\" #@param {type:\"string\"}\n",
    "within_community_probability = 0.39 #@param {type:\"slider\", min:0.01, max:1.0, step:0.01}\n",
    "between_community_probability = 0.138 #@param {type:\"slider\", min:0.001, max:0.5, step:0.001}\n",
    "\n",
    "#@markdown ## Random Geometric Parameters\n",
    "radius = 0.25 #@param {type:\"slider\", min:0.05, max:0.5, step:0.01}\n",
    "dimensions = 2 #@param {type:\"slider\", min:2, max:3, step:1}\n",
    "\n",
    "#@markdown ## Barabási-Albert Parameters\n",
    "m_new_edges = 2 #@param {type:\"slider\", min:1, max:10, step:1}\n",
    "\n",
    "#@markdown ## Watts-Strogatz Parameters\n",
    "n_nearest_neighbors = 6 #@param {type:\"slider\", min:2, max:10, step:1}\n",
    "rewiring_probability = 0.06 #@param {type:\"slider\", min:0.01, max:1.0, step:0.01}\n",
    "\n",
    "# Use JavaScript to hide irrelevant parameter sections based on the model type\n",
    "display(HTML(f'''\n",
    "<script>\n",
    "// Use the selected model from Python\n",
    "var selectedModel = \"{selected_model}\";\n",
    "\n",
    "// Function to hide irrelevant parameter sections\n",
    "function hideIrrelevantParameters() {{\n",
    "    var formGroups = document.querySelectorAll('.form-group');\n",
    "\n",
    "    for (var i = 0; i < formGroups.length; i++) {{\n",
    "        var text = formGroups[i].innerText || '';\n",
    "\n",
    "        // Keep common parameters visible\n",
    "        if (text.includes('Common Parameters')) {{\n",
    "            continue;\n",
    "        }}\n",
    "\n",
    "\n",
    "        // Hide/show based on model type\n",
    "        if (selectedModel === \"Erdos-Renyi\") {{\n",
    "          if (text.includes('Stochastic Block Model Parameters') ||\n",
    "                text.includes('Random Geometric Parameters') ||\n",
    "                text.includes('Barabasi–Albert Parameters') ||\n",
    "                text.includes('Watts–Strogatz Parameters')) {{\n",
    "                formGroups[i].style.display = 'none';\n",
    "            }}\n",
    "\n",
    "        }} else if (selectedModel === \"Stochastic Block Model\") {{\n",
    "            if (text.includes('Erdos-Renyi Parameters') ||\n",
    "                text.includes('Random Geometric Parameters') ||\n",
    "                text.includes('Barabasi–Albert Parameters') ||\n",
    "                text.includes('Watts–Strogatz Parameters')) {{\n",
    "                formGroups[i].style.display = 'none';\n",
    "            }}\n",
    "        }} else if (selectedModel === \"Random Geometric\") {{\n",
    "            if (text.includes('Erdos-Renyi Parameters') ||\n",
    "                text.includes('Stochastic Block Model Parameters') ||\n",
    "                text.includes('Barabasi-Albert Parameters') ||\n",
    "                text.includes('Watts-Strogatz Parameters')) {{\n",
    "                formGroups[i].style.display = 'none';\n",
    "            }}\n",
    "        }} else if (selectedModel === \"Barabási-Albert\") {{\n",
    "            if (text.includes('Erdos-Renyi Parameters') ||\n",
    "                text.includes('Stochastic Block Model Parameters') ||\n",
    "                text.includes('Random Geometric Parameters') ||\n",
    "                text.includes('Watts–Strogatz Parameters')) {{\n",
    "                formGroups[i].style.display = 'none';\n",
    "            }}\n",
    "        }} else if (selectedModel === \"Watts-Strogatz\") {{\n",
    "            if (text.includes('Erdös-Rényi Parameters') ||\n",
    "                text.includes('Stochastic Block Model Parameters') ||\n",
    "                text.includes('Random Geometric Parameters') ||\n",
    "                text.includes('Barabasi-Albert Parameters')) {{\n",
    "                formGroups[i].style.display = 'none';\n",
    "\n",
    "            }}\n",
    "        }}\n",
    "    }}\n",
    "}}\n",
    "// Run after a short delay to ensure the DOM is fully loaded\n",
    "setTimeout(hideIrrelevantParameters, 500);\n",
    "</script>\n",
    "'''))\n",
    "\n",
    "# Create the appropriate graph based on the model type\n",
    "if selected_model == \"Erdös-Rényi\":\n",
    "    # Create Erdös-Rényi graph\n",
    "    G = nx.erdos_renyi_graph(n=num_nodes, p=probability, seed=seed, directed=directed)\n",
    "    title = f\"Erdös-Rényi Graph: {num_nodes} nodes, p={probability}\"\n",
    "    pos = nx.spring_layout(G, seed=seed)\n",
    "\n",
    "elif selected_model == \"Stochastic Block Model\":\n",
    "    # Process community sizes\n",
    "    try:\n",
    "        sizes = [int(s.strip()) for s in community_sizes.split(\",\")]\n",
    "        if len(sizes) != num_communities:\n",
    "            sizes = [num_nodes // num_communities] * num_communities\n",
    "    except:\n",
    "        sizes = [num_nodes // num_communities] * num_communities\n",
    "\n",
    "    # Ensure sizes sum to num_nodes\n",
    "    total = sum(sizes)\n",
    "    if total != num_nodes:\n",
    "        sizes[-1] += (num_nodes - total)\n",
    "\n",
    "    # Create probability matrix\n",
    "    p = [[between_community_probability for _ in range(num_communities)] for _ in range(num_communities)]\n",
    "    for i in range(num_communities):\n",
    "        p[i][i] = within_community_probability\n",
    "\n",
    "    # Create the graph\n",
    "    G = nx.stochastic_block_model(sizes, p, seed=seed)\n",
    "    title = f\"Stochastic Block Model: {num_communities} communities with {sizes} nodes\"\n",
    "    pos = nx.spring_layout(G, seed=seed)\n",
    "\n",
    "elif selected_model == \"Barabasi-Albert\":\n",
    "    G = nx.barabasi_albert_graph(n=num_nodes, m=m_new_edges, seed=seed)\n",
    "    title = f\"Barabasi-Albert Graph: {num_nodes} nodes, m={m_new_edges}\"\n",
    "    pos = nx.spring_layout(G, seed=seed)\n",
    "\n",
    "elif selected_model == \"Watts-Strogatz\":\n",
    "    G = nx.watts_strogatz_graph(n=num_nodes, k=n_nearest_neighbors, p=rewiring_probability, seed=seed)\n",
    "    title = f\"Watts-Strogatz Graph: {num_nodes} nodes, k={n_nearest_neighbors}, p={rewiring_probability}\"\n",
    "    pos = nx.spring_layout(G, seed=seed)\n",
    "\n",
    "else:  # Random Geometric\n",
    "    # Create Random Geometric graph\n",
    "    G = nx.random_geometric_graph(n=num_nodes, radius=radius, dim=dimensions, seed=seed)\n",
    "    title = f\"Random Geometric Graph: {num_nodes} nodes, radius={radius}, dim={dimensions}\"\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "\n",
    "# Draw the graph\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.title(title)\n",
    "\n",
    "# Add community colors for Stochastic Block Model\n",
    "if selected_model == \"Stochastic Block Model\":\n",
    "    # Get node communities from graph\n",
    "    communities = [data['block'] for _, data in G.nodes(data=True)]\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=communities, cmap=plt.cm.tab10, node_size=100)\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "elif selected_model == \"Barabasi–Albert\" or selected_model == \"Watts–Strogatz\":\n",
    "    nx.draw(G, pos, with_labels=show_labels, node_size=100, node_color='lightcoral',\n",
    "            edge_color='gray', alpha=0.7)\n",
    "\n",
    "else:\n",
    "    nx.draw(G, pos, with_labels=show_labels, node_size=100, node_color='lightblue',\n",
    "            edge_color='gray', alpha=0.7)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show graph statistics\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "print(f\"Average clustering coefficient: {round(nx.average_clustering(G), 4)}\")\n",
    "try:\n",
    "    if nx.is_connected(G):\n",
    "        print(f\"Average shortest path length: {round(nx.average_shortest_path_length(G), 4)}\")\n",
    "    else:\n",
    "        print(\"Graph is not connected - cannot compute average shortest path length\")\n",
    "except:\n",
    "    print(\"Could not compute average shortest path length (possibly directed graph)\")\n",
    "\n",
    "# Hide the code\n",
    "display(HTML('''\n",
    "<script>\n",
    "var cell = document.querySelector('.input');\n",
    "if (cell) cell.style.display = 'none';\n",
    "</script>\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "executionInfo": {
     "elapsed": 1481,
     "status": "ok",
     "timestamp": 1753173875160,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "r7BZ0AjOGTWU",
    "outputId": "56e0a811-0936-42c4-c686-4446bd82852d"
   },
   "outputs": [],
   "source": [
    "#@title Save Graph { display-mode: \"form\" }\n",
    "\n",
    "def sanitize_graph_for_graphml(G):\n",
    "    for _, data in G.nodes(data=True):\n",
    "        for key in list(data.keys()):\n",
    "            if isinstance(data[key], list) or isinstance(data[key], dict):\n",
    "                data[key] = str(data[key])\n",
    "                \n",
    "    for _, _, attrs in G.edges(data=True):\n",
    "        for key in list(attrs.keys()):\n",
    "            if isinstance(attrs[key], list) or isinstance(attrs[key], dict):\n",
    "                attrs[key] = str(attrs[key])\n",
    "\n",
    "    return G\n",
    "\n",
    "G = sanitize_graph_for_graphml(G)\n",
    "\n",
    "\n",
    "def save_graph(G, save_path):\n",
    "    import networkx as nx\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    #G = nx.read_graphml(file_path)\n",
    "\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    pastel_blue = '#ADD8E6'\n",
    "    node_size = 250\n",
    "\n",
    "    nx.draw(\n",
    "        G,\n",
    "        pos,\n",
    "        with_labels=False,\n",
    "        node_color=pastel_blue,\n",
    "        edge_color='black',\n",
    "        node_size=node_size,\n",
    "        width=0.5,\n",
    "        edgecolors='black',\n",
    "        linewidths=0.5\n",
    "    )\n",
    "\n",
    "\n",
    "    plt.savefig(save_path, format='png', dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#@markdown ###Paths to save graphml format and figure\n",
    "name_graphml = f\"{net}_graph.graphml\" #@param {type:\"string\"}\n",
    "nx.write_graphml(G, os.path.join(cwd, name_graphml))\n",
    "name_figure = f\"{net}_graph.png\" #@param {type:\"string\"}\n",
    "save_graph(G, os.path.join(cwd, name_figure))\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "#@markdown ###Paths to save graph informations in json file\n",
    "name_json = f\"{net}_info.json\" #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "stats = {\n",
    "    \"Number of nodes\": G.number_of_nodes(),\n",
    "    \"Number of edges\": G.number_of_edges(),\n",
    "    \"Average clustering coefficient\": round(nx.average_clustering(G), 4)\n",
    "}\n",
    "\n",
    "try:\n",
    "    if nx.is_connected(G):\n",
    "        stats[\"Average shortest path length\"] = round(nx.average_shortest_path_length(G), 4)\n",
    "    else:\n",
    "        stats[\"Average shortest path length\"] = \"Graph not connected\"\n",
    "except:\n",
    "    stats[\"Average shortest path length\"] = \"Error (possibly directed graph)\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    \"Erdos-Renyi\": {\n",
    "        \"p\": probability,\n",
    "        \"directed\": directed\n",
    "    },\n",
    "    \"Stochastic Block Model\": {\n",
    "        \"num_communities\": num_communities,\n",
    "        \"community_sizes\": community_sizes,\n",
    "        \"within_community_probability\": within_community_probability,\n",
    "        \"between_community_probability\": between_community_probability\n",
    "    },\n",
    "    \"Barabasi-Albert\": {\n",
    "        \"m_new_edge\": m_new_edges\n",
    "    },\n",
    "    \"Watts-Strogatz\": {\n",
    "        \"n_nearest_neighbors\": n_nearest_neighbors,\n",
    "        \"rewiring_probability\": rewiring_probability\n",
    "    },\n",
    "    \"Random Geometric\": {\n",
    "        \"radius\": radius,\n",
    "        \"dimensions\": dimensions\n",
    "    }\n",
    "}\n",
    "\n",
    "output = {\n",
    "    \"Graph type\": selected_model,\n",
    "    \"Model parameters\": model_params[selected_model]\n",
    "}\n",
    "\n",
    "with open(os.path.join(cwd, name_json), \"w\") as f:\n",
    "    json.dump(output, f, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "# Hide the code\n",
    "display(HTML('''\n",
    "<script>\n",
    "var cell = document.querySelector('.input');\n",
    "if (cell) cell.style.display = 'none';\n",
    "</script>\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1753174071732,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "ZsRzPqxFK0DV",
    "outputId": "52081caa-1e7b-4d98-c52f-60f3e6cbc967"
   },
   "outputs": [],
   "source": [
    "#@title SIRVD Model Parameters { display-mode: \"form\" }\n",
    "#@markdown ## Configure SIRVD Model Parameters\n",
    "\n",
    "\n",
    "#@markdown ### Mortality and Vaccination Parameters\n",
    "MU_H = 0.00003 #@param {type:\"slider\", min:0.0, max:0.05, step:0.00001}\n",
    "#@markdown Natural human mortality rate\n",
    "\n",
    "RV_H = 0.1 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
    "#@markdown Probability of random vaccination\n",
    "\n",
    "BV_H = 0.7 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
    "#@markdown Probability of targeted vaccination\n",
    "\n",
    "NV_H = 0 #@param {type:\"slider\", min:0.0, max:0.01, step:0}\n",
    "#@markdown No vaccination\n",
    "\n",
    "#@markdown ### Infection Parameters\n",
    "BETA_H = 0.09 #@param {type:\"slider\", min:0.0, max:0.1, step:0.00001}\n",
    "#@markdown Probability of infection\n",
    "\n",
    "BETA_HV = 0.008 #@param {type:\"slider\", min:0.0, max:0.1, step:0.00001}\n",
    "#@markdown Probability of becoming infected for a vaccinated individual\n",
    "\n",
    "GAMMA_H = 0.001 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
    "#@markdown Probability of recovery\n",
    "\n",
    "DELTA_H = 0.0005 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
    "#@markdown Mortality rate for infected individuals\n",
    "name_params_json = f\"{net}_params_SIRVD.json\" #@param {type:\"string\"}\n",
    "#@markdown Path to save in a json file the parameters\n",
    "\n",
    "name_params_json = f\"{net}_params_SIRVD.json\" #@param {type:\"string\"}\n",
    "#@markdown Path to save in a json file the parameters\n",
    "\n",
    "# Store parameters in a dictionary\n",
    "params = {\n",
    "    \"MU_H\": MU_H,\n",
    "    \"V_H\": NV_H,\n",
    "    \"BETA_H\": BETA_H,\n",
    "    \"BETA_HV\": BETA_HV,\n",
    "    \"GAMMA_H\": GAMMA_H,\n",
    "    \"DELTA_H\": DELTA_H\n",
    "}\n",
    "\n",
    "params_vax = params.copy()\n",
    "params_vax[\"V_H\"] = RV_H\n",
    "\n",
    "params_vax_target = params.copy()\n",
    "params_vax_target[\"V_H\"] = BV_H\n",
    "\n",
    "sim_params = {\n",
    "    \"no_vax\": params,\n",
    "    \"vax\": params_vax,\n",
    "    \"vax_target\": params_vax_target\n",
    "}\n",
    "\n",
    "# Display the current parameter values in a formatted way\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "# Create a summary table of the parameters\n",
    "parameters_summary = \"\"\"\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| MU_H | {:.5f} | Natural human mortality |\n",
    "| V_H_r | {:.2f} | Probability of random vaccination |\n",
    "| V_H_t | {:.2f} | Probability of tageted vaccination |\n",
    "| V_H_no | {:.2f} | No vaccination |\n",
    "| BETA_H | {:.6f} | Probability of becoming infected when susceptible |\n",
    "| BETA_HV | {:.6f} | Probability of becoming infected for a vaccinated individual |\n",
    "| GAMMA_H | {:.5f} | Probability of recovery |\n",
    "| DELTA_H | {:.5f} | Mortality rate for infected individuals |\n",
    "\"\"\".format(MU_H, RV_H, BV_H, NV_H, BETA_H, BETA_HV,GAMMA_H, DELTA_H)\n",
    "\n",
    "display(Markdown(parameters_summary))\n",
    "\n",
    "\n",
    "with open(os.path.join(cwd, name_params_json), \"w\") as f:\n",
    "    json.dump(sim_params, f, indent=4)\n",
    "\n",
    "# Hide the code\n",
    "display(HTML('''\n",
    "<script>\n",
    "var cell = document.querySelector('.input');\n",
    "if (cell) cell.style.display = 'none';\n",
    "</script>\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 36519,
     "status": "ok",
     "timestamp": 1753174171144,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "5lPFacL3TrgJ",
    "outputId": "4d06eecd-3112-46da-81cf-aa534d986146"
   },
   "outputs": [],
   "source": [
    "#@title SIRVD simulations { display-mode: \"form\" }\n",
    "\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def initial_state(G):\n",
    "\n",
    "    state = {}\n",
    "\n",
    "    for node in G.nodes:\n",
    "        state[node] = \"Sh\"\n",
    "    print(state)\n",
    "    # Randomly select patient zero (one human)\n",
    "    paziente_zero_h = random.choice([node for node, s in state.items() if s == \"Sh\"])\n",
    "    state[paziente_zero_h] = \"Ih\"  # Set one human as infected\n",
    "\n",
    "    nx.set_node_attributes(G, state, 'state')\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def count_nodestates(current_state):\n",
    "    # Count number of nodes for each state\n",
    "    count = {\n",
    "        'Sh': sum(1 for state in current_state.values() if state == 'Sh'),\n",
    "        'Ih': sum(1 for state in current_state.values() if state == 'Ih'),\n",
    "        'Rh': sum(1 for state in current_state.values() if state == 'Rh'),\n",
    "        'Vh': sum(1 for state in current_state.values() if state == 'Vh'),\n",
    "        'Dh': sum(1 for state in current_state.values() if state == 'Dh'),\n",
    "    }\n",
    "    return count\n",
    "\n",
    "def count_nodetypes(current_state):\n",
    "    count = {\n",
    "        'human': sum(1 for state in current_state.values() if state[-1] == \"h\"),\n",
    "    }\n",
    "    return count\n",
    "\n",
    "\n",
    "def state_transition(G, current_state, prec_states, params, step, vaccination_type=\"random\"):\n",
    "    next_state = current_state.copy()\n",
    "\n",
    "    count_states = count_nodestates(current_state)\n",
    "    count_types = count_nodetypes(current_state)\n",
    "\n",
    "    if step % 50 == 0 or step == 400:\n",
    "        print(f\"Step {step}: {count_states}\")\n",
    "\n",
    "    # ---- VACCINATION ----\n",
    "    if vaccination_type == \"betweenness\":\n",
    "        centrality = nx.betweenness_centrality(G, k=100, seed=42)\n",
    "        sorted_nodes = sorted(centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_nodes = [node for node, _ in sorted_nodes[:int(len(G) * 0.30)]]\n",
    "\n",
    "        for node in top_nodes:\n",
    "            if current_state[node] == \"Sh\" and random.random() < params[\"V_H\"]:\n",
    "                next_state[node] = \"Vh\"\n",
    "\n",
    "\n",
    "    elif vaccination_type == \"random\":\n",
    "        for node in G.nodes:\n",
    "            if current_state[node] == \"Sh\" and random.random() < params[\"V_H\"]:\n",
    "                next_state[node] = \"Vh\"\n",
    "\n",
    "\n",
    "    # ---- STATE TRANSITION----\n",
    "    for node in G.nodes:\n",
    "        state = current_state[node]\n",
    "\n",
    "        if state == \"Sh\":\n",
    "            if random.random() < params[\"MU_H\"]:\n",
    "                next_state[node] = \"Dh\"\n",
    "            else:\n",
    "                for neighbor in G.neighbors(node):\n",
    "                    if current_state[neighbor] == \"Ih\":\n",
    "                        if random.random() < params[\"BETA_H\"]:\n",
    "                            next_state[node] = \"Ih\"\n",
    "                            break\n",
    "\n",
    "        elif state == \"Vh\":\n",
    "            if random.random() < params[\"MU_H\"]:\n",
    "                next_state[node] = \"Dh\"\n",
    "            else:\n",
    "                for neighbor in G.neighbors(node):\n",
    "                    if current_state[neighbor] == \"Ih\":\n",
    "                        if random.random() < params[\"BETA_HV\"]:\n",
    "                            next_state[node] = \"Ih\"\n",
    "                            break\n",
    "\n",
    "        elif state == \"Ih\":\n",
    "            if random.random() < (params[\"MU_H\"] + params[\"DELTA_H\"]):\n",
    "                next_state[node] = \"Dh\"\n",
    "            elif random.random() < params[\"GAMMA_H\"]:\n",
    "                next_state[node] = \"Rh\"\n",
    "\n",
    "        elif state == \"Rh\":\n",
    "            if random.random() < params[\"MU_H\"]:\n",
    "                next_state[node] = \"Dh\"\n",
    "\n",
    "\n",
    "    return next_state\n",
    "\n",
    "\n",
    "class StopCondition(StopIteration):\n",
    "    pass #no stop conditions for now\n",
    "\n",
    "class Simulation:\n",
    "    '''Simulate state transitions on a network graph\n",
    "\n",
    "        Simulation class for Chapter 7 Tutorial of Intro Network Science book\n",
    "        Copyright 2018 Indiana University and Cambridge University Press\n",
    "        https://github.com/CambridgeUniversityPress/FirstCourseNetworkScience/blob/master/tutorials/simulation.py\n",
    "    '''\n",
    "\n",
    "    def __init__(self, G, initial_state, state_transition, params,\n",
    "                 stop_condition=None, vaccination_type = \"random\", name=''):\n",
    "        '''\n",
    "        Initialize a Simulation instance.\n",
    "\n",
    "        Args:\n",
    "            G: A networkx.Graph instance representing the network.\n",
    "            initial_state: Function with signature `initial_state(G)` that\n",
    "                takes the graph as input and returns a dictionary of initial\n",
    "                states for each node, where keys are node names and values are\n",
    "                initial states.\n",
    "            state_transition: Function with signature `state_transition(G, current_state)`\n",
    "                that takes the graph and a dictionary of current node states, and returns\n",
    "                updated states for each node.\n",
    "            stop_condition (optional): Function with signature `stop_condition(G, current_state)`\n",
    "                that takes the graph and the current states dictionary, returning True if\n",
    "                the simulation should stop.\n",
    "\n",
    "        Keyword Args:\n",
    "            name (optional): A string for naming the simulation, used in plot titles.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If not all graph nodes have an initial state.\n",
    "\n",
    "        '''\n",
    "        self.G = G.copy()\n",
    "        self._initial_state = initial_state\n",
    "        self._state_transition = state_transition\n",
    "        self._stop_condition = stop_condition\n",
    "        self.params = params\n",
    "        self.vaccination_type = vaccination_type\n",
    "\n",
    "        # Ensure stop_condition is callable if provided\n",
    "        if stop_condition and not callable(stop_condition):\n",
    "            raise TypeError(\"'stop_condition' should be a function\")\n",
    "\n",
    "        self.name = name or 'Simulation'\n",
    "\n",
    "        # Initialize state storage and mapping variables\n",
    "        self._states = []                    # Holds the states of all nodes at each step\n",
    "        self._value_index = {}\n",
    "        self._cmap = plt.cm.get_cmap('tab20') # Matplotlib colormap for node color coding\n",
    "\n",
    "        self._initialize()                   # Run initial setup for nodes' states\n",
    "\n",
    "        # Set up node positions for consistent layout in visualizations\n",
    "        self._pos = nx.layout.spring_layout(G)\n",
    "\n",
    "    def _append_state(self, state):\n",
    "        '''Append the current state to the state list and update unique state index mapping.'''\n",
    "        self._states.append(state)           # Save current state to state history\n",
    "\n",
    "        # Update state mapping for new values\n",
    "        for value in set(state.values()):\n",
    "            if value not in self._value_index:\n",
    "                self._value_index[value] = len(self._value_index)  # Assign a new index to unseen states\n",
    "\n",
    "    def _initialize(self):\n",
    "        '''Set initial states for nodes and ensure all nodes have an assigned state.'''\n",
    "        if self._initial_state:\n",
    "            # Determine initial state based on provided function or dictionary\n",
    "            state = self._initial_state(self.G) if callable(self._initial_state) else self._initial_state\n",
    "            nx.set_node_attributes(self.G, state, 'state')  # Apply initial states to nodes as attributes\n",
    "\n",
    "        # Check that all nodes have been assigned an initial state\n",
    "        if any(self.G.nodes[n].get('state') is None for n in self.G.nodes):\n",
    "            raise ValueError('All nodes must have an initial state')\n",
    "\n",
    "        self._append_state(state)  # Save initial state as the first entry in state history\n",
    "\n",
    "    def _step(self):\n",
    "        '''Perform a single step of the simulation, updating states for each node.'''\n",
    "        state = nx.get_node_attributes(self.G, 'state')  # Retrieve current node states\n",
    "\n",
    "        # Check if stop condition is met\n",
    "        if self._stop_condition and self._stop_condition(self.G, state):\n",
    "            raise StopCondition  # Stop simulation if condition is met\n",
    "\n",
    "        step = len(self._states) - 1  # Current step index\n",
    "        new_state = self._state_transition(self.G, state, self._states, self.params, step, self.vaccination_type)  # Compute new states based on transition function\n",
    "        state.update(new_state)                            # Update the current state with new values\n",
    "        nx.set_node_attributes(self.G, state, 'state')     # Apply updated states to nodes as attributes\n",
    "        self._append_state(state)                          # Record new state in history\n",
    "\n",
    "    def _categorical_color(self, value):\n",
    "        '''Return color for a node based on its state value.'''\n",
    "        index = self._value_index[value]        # Retrieve color index for the state\n",
    "        return self._cmap(index)                # Return color from colormap for given index\n",
    "\n",
    "    @property\n",
    "    def steps(self):\n",
    "        '''Return the number of steps the simulation has run.'''\n",
    "        return len(self._states) - 1\n",
    "\n",
    "    def state(self, step=-1):\n",
    "        '''\n",
    "        Retrieve a specific state of the simulation, defaulting to the latest state.\n",
    "\n",
    "        Args:\n",
    "            step: The step index to retrieve; defaults to -1 for the latest state.\n",
    "\n",
    "        Returns:\n",
    "            Dictionary of node states.\n",
    "\n",
    "        Raises:\n",
    "            IndexError: If requested step is beyond available steps.\n",
    "        '''\n",
    "        try:\n",
    "            return self._states[step]\n",
    "        except IndexError:\n",
    "            raise IndexError(f'Simulation step {step} out of range')\n",
    "\n",
    "    def draw(self, step=-1, labels=None, **kwargs):\n",
    "        '''\n",
    "        Draw a simulation state, coloring nodes by their state values.\n",
    "\n",
    "        Args:\n",
    "            step: The step index to draw; defaults to -1 for the latest state.\n",
    "            kwargs: Additional arguments for networkx.draw()\n",
    "\n",
    "        Raises:\n",
    "            IndexError: If requested step is beyond available steps.\n",
    "        '''\n",
    "        state = self.state(step)\n",
    "        node_colors = [self._categorical_color(state[n]) for n in self.G.nodes]\n",
    "        nx.draw(self.G, pos=self._pos, node_color=node_colors, **kwargs)\n",
    "\n",
    "        # Configure and display legend for unique states\n",
    "        if labels is None:\n",
    "            labels = set(state.values())\n",
    "        patches = [mpl.patches.Patch(color=self._categorical_color(l), label=l)\n",
    "                   for l in labels]\n",
    "        plt.legend(handles=patches)\n",
    "\n",
    "        # Set title to display the current step or 'initial state' if at step 0\n",
    "        step_title = 'initial state' if step == 0 else f'step {step}'\n",
    "        plt.title(f'{self.name}: {step_title}')\n",
    "\n",
    "    def plot(self, min_step=None, max_step=None, labels=None, **kwargs):\n",
    "        '''\n",
    "        Plot the proportion of nodes in each state over the simulation steps.\n",
    "\n",
    "        Args:\n",
    "            min_step: First step to include in the plot (defaults to start of simulation).\n",
    "            max_step: Last step to include in the plot, non-inclusive (defaults to latest step).\n",
    "            labels: Ordered sequence of states to plot (defaults to all observed states).\n",
    "            kwargs: Additional arguments for plt.plot()\n",
    "\n",
    "        Returns:\n",
    "            Matplotlib Axes object for the current plot.\n",
    "        '''\n",
    "        x_range = range(min_step or 0, max_step or len(self._states))\n",
    "        counts = [Counter(s.values()) for s in self._states[min_step:max_step]]\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        if labels is None:\n",
    "            labels = sorted({k for count in counts for k in count}, key=self._value_index.get)\n",
    "\n",
    "        # Plot proportion of nodes in each state over steps\n",
    "        for label in labels:\n",
    "            series = [count.get(label, 0) / sum(count.values()) for count in counts]\n",
    "            plt.plot(x_range, series, label=label, **kwargs)\n",
    "\n",
    "        # Configure plot labels and title\n",
    "        plt.title(f'{self.name}: node state proportions')\n",
    "        plt.xlabel('Simulation step')\n",
    "        plt.ylabel('Proportion of nodes')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xlim(x_range.start)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def run(self, steps=1):\n",
    "        '''\n",
    "        Run the simulation for a specified number of steps.\n",
    "\n",
    "        Args:\n",
    "            steps: Number of steps to advance the simulation (default is 1).\n",
    "        '''\n",
    "        for _ in range(steps):\n",
    "            try:\n",
    "                self._step()\n",
    "            except StopCondition:\n",
    "                print(f\"Stop condition met at step {self.steps}\")\n",
    "                break\n",
    "\n",
    "def categorical_color(value_index, value):\n",
    "  '''Return color for a node based on its state value.'''\n",
    "  cmap = plt.cm.get_cmap('tab20') # Matplotlib colormap for node color coding\n",
    "  index = value_index[value]      # Retrieve color index for the state\n",
    "  return cmap(index)               # Return color from colormap for given index\n",
    "\n",
    "\n",
    "#@markdown ### Number of iteration steps\n",
    "steps = 400 #@param {type:\"slider\", min:1.0, max:1000, step:1}\n",
    "#@markdown Number of iteration steps\n",
    "\n",
    "\n",
    "\n",
    "sims = {}\n",
    "for type, sim in sim_params.items():\n",
    "\n",
    "  if \"target\" in type:\n",
    "    sims[type] = Simulation(G, initial_state, state_transition, sim, vaccination_type=\"betweenness\", name=f\"Simulation {type} vaccination betweenness\")\n",
    "  else:\n",
    "    sims[type] = Simulation(G, initial_state, state_transition, sim, name=f\"Simulation {type}\")\n",
    "  sims[type].run(steps)\n",
    "  fig = sims[type].plot()\n",
    "  fig.savefig(os.path.join(cwd, f\"sim_{type}_{net}.png\"), dpi = 600)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10742,
     "status": "ok",
     "timestamp": 1753174193229,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "IhBSfsjLaWLc",
    "outputId": "4083d1f5-867a-463b-819e-6dbb9823ad5e"
   },
   "outputs": [],
   "source": [
    "#@title SIRVD Model Visualization { display-mode: \"form\" }\n",
    "#@markdown ### Select states and vaccination strategies to visualize\n",
    "\n",
    "#@markdown ## Select states to plot\n",
    "plot_infected = True #@param {type:\"boolean\"}\n",
    "plot_dead = True #@param {type:\"boolean\"}\n",
    "plot_susceptible = True #@param {type:\"boolean\"}\n",
    "plot_recovered = True #@param {type:\"boolean\"}\n",
    "plot_vaccinated = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ## Select vaccination strategies to compare\n",
    "show_targeted_vaccination = True #@param {type:\"boolean\"}\n",
    "show_random_vaccination = True #@param {type:\"boolean\"}\n",
    "show_no_vaccination = True #@param {type:\"boolean\"}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# Map selections to state codes\n",
    "states_to_plot = []\n",
    "if plot_infected:\n",
    "    states_to_plot.append(\"Ih\")\n",
    "if plot_dead:\n",
    "    states_to_plot.append(\"Dh\")\n",
    "if plot_susceptible:\n",
    "    states_to_plot.append(\"Sh\")\n",
    "if plot_recovered:\n",
    "    states_to_plot.append(\"Rh\")\n",
    "if plot_vaccinated:\n",
    "    states_to_plot.append(\"Vh\")\n",
    "\n",
    "# Map selections to strategy keys\n",
    "strategies_to_plot = []\n",
    "if show_targeted_vaccination:\n",
    "    strategies_to_plot.append(\"vax_target\")\n",
    "if show_random_vaccination:\n",
    "    strategies_to_plot.append(\"vax\")\n",
    "if show_no_vaccination:\n",
    "    strategies_to_plot.append(\"no_vax\")\n",
    "\n",
    "# Verify we have at least one state and strategy selected\n",
    "if not states_to_plot:\n",
    "    print(\"Error: Please select at least one state to plot\")\n",
    "\n",
    "if not strategies_to_plot:\n",
    "    print(\"Error: Please select at least one vaccination strategy\")\n",
    "\n",
    "# If selections are valid, continue with plotting\n",
    "if states_to_plot and strategies_to_plot:\n",
    "    # Create dictionary to store data for plotting\n",
    "    to_plot_strategies = {}\n",
    "\n",
    "    # Process data from simulations\n",
    "    for type, sim in sims.items():\n",
    "        if type not in strategies_to_plot:\n",
    "            continue\n",
    "\n",
    "        temp = {st: [] for st in states_to_plot}\n",
    "        for step in range(steps):\n",
    "            states = sim.state(step=step)\n",
    "            count_states = Counter(states.values())\n",
    "            den = sum(count_states.values())\n",
    "            for st in states_to_plot:\n",
    "                if st in count_states:\n",
    "                    temp[st].append(count_states[st]/den)\n",
    "                else:\n",
    "                    temp[st].append(0)  # Handle missing states\n",
    "\n",
    "        to_plot_strategies[type] = temp\n",
    "\n",
    "    # Create plots\n",
    "    for st in states_to_plot:\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        title = \"\"\n",
    "        # Set appropriate title\n",
    "        if st == \"Ih\":\n",
    "            plt.title(\"Infected Humans\")\n",
    "            title = \"Infected Humans\"\n",
    "        elif st == \"Dh\":\n",
    "            plt.title(\"Dead Humans\")\n",
    "            title = \"Dead Humans\"\n",
    "        elif st == \"Rh\":\n",
    "            plt.title(\"Recovered Humans\")\n",
    "            title = \"Recovered Humans\"\n",
    "        elif st == \"Sh\":\n",
    "            plt.title(\"Susceptible Humans\")\n",
    "            title = \"Susceptible Humans\"\n",
    "        elif st == \"Vh\":\n",
    "            plt.title(\"Vaccinated Humans\")\n",
    "            title = \"Vaccinated Humans\"\n",
    "\n",
    "        plt.title(title)\n",
    "        # Plot each selected strategy\n",
    "        for strategy in strategies_to_plot:\n",
    "            if strategy in to_plot_strategies and st in to_plot_strategies[strategy]:\n",
    "                label = {\n",
    "                    \"vax_target\": \"Targeted Vaccination\",\n",
    "                    \"vax\": \"Random Vaccination\",\n",
    "                    \"no_vax\": \"No Vaccination\"\n",
    "                }.get(strategy, strategy)\n",
    "\n",
    "                plt.plot(to_plot_strategies[strategy][st], label=label)\n",
    "\n",
    "        plt.xlabel(\"Simulation Steps\")\n",
    "        plt.ylabel(f\"Proportion of nodes in state {st}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        fig.savefig(os.path.join(cwd, f\"{title}_{net}.png\"), dpi=600)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Hide the code\n",
    "from IPython.display import display, HTML\n",
    "display(HTML('''\n",
    "<script>\n",
    "var cell = document.querySelector('.input');\n",
    "if (cell) cell.style.display = 'none';\n",
    "</script>\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "executionInfo": {
     "elapsed": 2232,
     "status": "ok",
     "timestamp": 1753174195470,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "zw6tDWX-f9l4",
    "outputId": "b3edd67b-3b55-48b9-db5f-e7c0ea4664e0"
   },
   "outputs": [],
   "source": [
    "#@title Select Simulation Step for Training { display-mode: \"form\" }\n",
    "#@markdown ### Select a specific simulation step to use for training\n",
    "\n",
    "train_step = 55 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "#@markdown Select which simulation states to display\n",
    "\n",
    "show_infected = True #@param {type:\"boolean\"}\n",
    "show_susceptible = True #@param {type:\"boolean\"}\n",
    "show_vaccinated = True #@param {type:\"boolean\"}\n",
    "show_recovered = True #@param {type:\"boolean\"}\n",
    "show_dead = True #@param {type:\"boolean\"}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Setup\n",
    "states_to_show = []\n",
    "if show_infected: states_to_show.append(\"Ih\")\n",
    "if show_susceptible: states_to_show.append(\"Sh\")\n",
    "if show_vaccinated: states_to_show.append(\"Vh\")\n",
    "if show_recovered: states_to_show.append(\"Rh\")\n",
    "if show_dead: states_to_show.append(\"Dh\")\n",
    "\n",
    "state_names = {\n",
    "    \"Ih\": \"Infected\",\n",
    "    \"Sh\": \"Susceptible\",\n",
    "    \"Vh\": \"Vaccinated\",\n",
    "    \"Rh\": \"Recovered\",\n",
    "    \"Dh\": \"Dead\"\n",
    "}\n",
    "\n",
    "'''\n",
    "color_map = {\n",
    "    \"Ih\": \"red\",\n",
    "    \"Sh\": \"blue\",\n",
    "    \"Eh\": \"orange\",\n",
    "    \"Rh\": \"green\",\n",
    "    \"Dh\": \"black\"\n",
    "}\n",
    "'''\n",
    "\n",
    "color_map = {\n",
    "    \"Ih\": \"lightcoral\",\n",
    "    \"Sh\": \"lightblue\",\n",
    "    \"Eh\": \"peachpuff\",\n",
    "    \"Rh\": \"lightgreen\",\n",
    "    \"Dh\": \"lightgray\"\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(1, len(sims), figsize=(15, 5), sharey=True)\n",
    "fig.suptitle(f'State Distribution at Step {train_step}', fontsize=16)\n",
    "\n",
    "summary_by_strategy = {}\n",
    "\n",
    "for i, (type_name, sim) in enumerate(sims.items()):\n",
    "    states = sim.state(step=train_step)\n",
    "    count_states = Counter(states.values())\n",
    "    total = sum(count_states.values())\n",
    "\n",
    "    labels, values, colors = [], [], []\n",
    "\n",
    "    strategy_label = {\n",
    "        \"vax_target\": \"Targeted Vaccination\",\n",
    "        \"vax\": \"Random Vaccination\",\n",
    "        \"no_vax\": \"No Vaccination\"\n",
    "    }.get(type_name, type_name)\n",
    "\n",
    "    strategy_data = {}\n",
    "\n",
    "    for state in states_to_show:\n",
    "        if state in count_states:\n",
    "            label = state_names.get(state, state)\n",
    "            count = count_states[state]\n",
    "            perc = round(count / total * 100, 1)\n",
    "\n",
    "            labels.append(label)\n",
    "            values.append(perc)\n",
    "            colors.append(color_map.get(state, \"gray\"))\n",
    "\n",
    "\n",
    "            strategy_data[label] = {\n",
    "                \"nodes\": count,\n",
    "                \"percentage\": perc\n",
    "            }\n",
    "\n",
    "\n",
    "    summary_by_strategy[strategy_label] = strategy_data\n",
    "\n",
    "    # Pie chart\n",
    "    ax[i].pie(values, labels=labels, autopct='%1.1f%%', colors=colors)\n",
    "    ax[i].set_title(strategy_label)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(cwd, f\"states_step_{train_step}_{net}.png\"), dpi=600)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "json_path = os.path.join(cwd, f\"state_distribution_step_{train_step}_{net}.json\")\n",
    "\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(summary_by_strategy, f, indent=4)\n",
    "\n",
    "print(f\"\\n State distribution saved to {json_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Print state percentages\n",
    "print(f\"Selected step {train_step} for training\")\n",
    "print(\"State distribution at this step:\")\n",
    "\n",
    "for sim_name, sim in sims.items():\n",
    "    states = sim.state(step=train_step)\n",
    "    count_states = Counter(states.values())\n",
    "    total = sum(count_states.values())\n",
    "\n",
    "    print(f\"\\n{sim_name}:\")\n",
    "    for state in states_to_show:\n",
    "        count = count_states.get(state, 0)\n",
    "        percent = count / total * 100 if total > 0 else 0\n",
    "        print(f\"  {state_names[state]}: {count} nodes ({percent:.1f}%)\")\n",
    "\n",
    "\n",
    "display(HTML('''\n",
    "<script>\n",
    "var cell = document.querySelector('.input');\n",
    "if (cell) cell.style.display = 'none';\n",
    "</script>\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1753174195485,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "bw-vCLd48nDX",
    "outputId": "7610200f-b3e6-45c6-fb2f-88b090cdfda0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "np.__version__, scipy.__version__, sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-Y_uKg_TGFj"
   },
   "source": [
    "GCN part: predict next simulation step with k-GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sxRk14rfmGJ"
   },
   "outputs": [],
   "source": [
    "#@markdown ### Install Deep Learning libraries\n",
    "!pip install torch_geometric\n",
    "!pip install captum\n",
    "#@markdown Install Deep Learning libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 20720,
     "status": "ok",
     "timestamp": 1753174966996,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "L6QBYGk9rnpE",
    "outputId": "9e5dd41d-4edd-4275-a720-8a650cffa817"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import time\n",
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "#from umap import UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def parse_edges(edge_list):\n",
    "\n",
    "    source_nodes = []\n",
    "    target_nodes = []\n",
    "    node_mapping = {}\n",
    "    next_index = 0\n",
    "\n",
    "    for edge in edge_list:\n",
    "        source, target = edge\n",
    "        #if source == target:\n",
    "        #    continue\n",
    "        if source not in node_mapping:\n",
    "            node_mapping[source] = next_index\n",
    "            next_index += 1\n",
    "        if target not in node_mapping:\n",
    "            node_mapping[target] = next_index\n",
    "            next_index += 1\n",
    "\n",
    "        source_nodes.append(node_mapping[source])\n",
    "        target_nodes.append(node_mapping[target])\n",
    "\n",
    "    return source_nodes, target_nodes, node_mapping\n",
    "\n",
    "def create_edge_index(source_nodes, target_nodes):\n",
    "    edge_list = np.array([source_nodes, target_nodes], dtype=np.int64)\n",
    "    edge_index = torch.LongTensor(edge_list)\n",
    "    return edge_index\n",
    "\n",
    "def labels_to_int(y):\n",
    "\n",
    "  labels_map = {}\n",
    "  labels_int = []\n",
    "\n",
    "  uq_y = np.unique(y)\n",
    "\n",
    "  for i, label in enumerate(uq_y):\n",
    "    labels_map[label] = i\n",
    "\n",
    "  for i, label in enumerate(y):\n",
    "    labels_int.append(labels_map[label])\n",
    "\n",
    "  return labels_int, labels_map\n",
    "\n",
    "def create_dataloader(sim, step=-1, vax=True):\n",
    "    prec_state = sim.state(step=step-1)  # Previous state\n",
    "    state = sim.state(step=step)        # Current state\n",
    "\n",
    "    # Labels (y)\n",
    "    y = [label for node, label in state.items()]\n",
    "    y, labels_map = labels_to_int(y)\n",
    "    y = torch.tensor(y).to(device)\n",
    "\n",
    "    # Features from previous state\n",
    "    nx.set_node_attributes(sim.G, prec_state, 'prec_state')\n",
    "\n",
    "    node_death = [1 if prec_state[node] == \"Dh\" else 0 for node in sim.G.nodes]\n",
    "    node_death = torch.tensor(node_death).float().to(device)\n",
    "\n",
    "    if vax:\n",
    "        node_vax = [1 if prec_state[node] == \"Vh\" else 0 for node in sim.G.nodes]\n",
    "        node_vax = torch.tensor(node_vax).float().to(device)\n",
    "\n",
    "    # Count infected neighbors\n",
    "    infected_neighbors_human = []\n",
    "    for node in sim.G.nodes:\n",
    "        if prec_state[node] == \"Dh\":\n",
    "            infected_neighbors_human.append(0.0)\n",
    "        else:\n",
    "            neighbors = list(sim.G.neighbors(node))\n",
    "            if not neighbors:\n",
    "                infected_neighbors_human.append(0.0)\n",
    "            else:\n",
    "                infected_count = sum(1 for neighbor in neighbors if state[neighbor] == 'Ih')\n",
    "                infected_neighbors_human.append(infected_count / len(neighbors))\n",
    "\n",
    "    infected_neighbors_human = torch.tensor(infected_neighbors_human).float().to(device)\n",
    "\n",
    "    # Encode prec_state as integers\n",
    "    prec_state = list(prec_state.values())\n",
    "    prec_state, _ = labels_to_int(prec_state)\n",
    "    prec_state = torch.tensor(prec_state).float().to(device)\n",
    "\n",
    "    # Build feature matrix\n",
    "    if vax:\n",
    "        x = torch.stack([prec_state, infected_neighbors_human, node_vax, node_death], dim=1)\n",
    "    else:\n",
    "        x = torch.stack([prec_state, infected_neighbors_human, node_death], dim=1)\n",
    "\n",
    "    # Build edge_index\n",
    "    edges = sim.G.edges\n",
    "    source_nodes, target_nodes, node_mapping = parse_edges(edges)\n",
    "    edge_index = create_edge_index(source_nodes, target_nodes)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "    return data, labels_map\n",
    "\n",
    "# Visualization function for NX graph or PyTorch tensor\n",
    "def visualize(save_info,h, colors, labels, epoch=None, loss=None, auc=None):\n",
    "\n",
    "    #colornames = ['blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'yellow', 'cyan', 'magenta', 'lime']\n",
    "    colornames = [\n",
    "    \"lightblue\",\n",
    "    \"orange\",\n",
    "    \"lightgreen\",\n",
    "    \"coral\",\n",
    "    \"plum\",\n",
    "    \"burlywood\",\n",
    "    \"lightpink\",\n",
    "    \"lightgray\",\n",
    "    \"lemonchiffon\",\n",
    "    \"powderblue\",\n",
    "    \"thistle\",\n",
    "    \"palegreen\"\n",
    "]\n",
    "\n",
    "    # Create scatter plot\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    umap = TSNE(n_components = 2)\n",
    "    if torch.is_tensor(h):\n",
    "        h = h.detach().cpu().numpy()\n",
    "    h = umap.fit_transform(h)\n",
    "\n",
    "\n",
    "    uq_colors = np.unique(colors)\n",
    "    for j, c in enumerate(uq_colors):\n",
    "      indices = [i for i, color in enumerate(colors) if color == c]\n",
    "      plt.scatter(h[indices, 0], h[indices, 1], s=50, label=labels[j], color = colornames[j], alpha=0.9)\n",
    "      if epoch is not None and loss is not None and auc['train'] is not None and auc['val'] is not None:\n",
    "        plt.xlabel((f'Epoch: {epoch}, Loss: {loss.item():.4f} \\n'\n",
    "                       f'Training AUC: {auc[\"train\"]} \\n'\n",
    "                       f' Validation AUC: {auc[\"val\"]}'),\n",
    "                       fontsize=16)\n",
    "\n",
    "    # Adjust legend\n",
    "    ax.legend(title=\"Legend\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(save_info, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "def compute_class_weights(labels):\n",
    "    \"\"\"\n",
    "    Computes class weights based on the distribution of labels.\n",
    "\n",
    "    :param labels: Tensor containing the class labels for each node.\n",
    "    :return: A tensor containing the class weights.\n",
    "    \"\"\"\n",
    "    # Calculate class weights using the sklearn library\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels.cpu()), y=labels.cpu().numpy())\n",
    "\n",
    "    # Convert the weights to a tensor\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(labels.device)\n",
    "\n",
    "    return class_weights_tensor\n",
    "\n",
    "\n",
    "    print(sim_type)\n",
    "    if \"no_vax\" in sim_type:\n",
    "      vax = False\n",
    "    else:\n",
    "      vax = True\n",
    "\n",
    "\n",
    "datas = {}\n",
    "labels_maps = {}\n",
    "\n",
    "for sim_type, sim in sims.items():\n",
    "    vax = True if \"no\" not in sim_type else False\n",
    "    data, labels_map = create_dataloader(sim, step=train_step, vax=vax)\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    train_size = 0.7  # 70% for training\n",
    "\n",
    "    y_cpu = data.y.cpu().numpy()\n",
    "    unique, counts = np.unique(y_cpu, return_counts=True)\n",
    "    print(f\"{sim_type} class distribution:\", counts)\n",
    "\n",
    "    indices = np.arange(0, num_nodes, 1)\n",
    "\n",
    "    #If a class has less than 2 samples,  disable sratify\n",
    "    if np.any(counts < 2):\n",
    "        print(f\"Stratified split disabled for '{sim_type}': at least one class has less than 2 samples.\")\n",
    "        train_indices, test_indices = train_test_split(indices, train_size=train_size, shuffle=True)\n",
    "    else:\n",
    "        train_indices, test_indices = train_test_split(indices, train_size=train_size, stratify=y_cpu)\n",
    "\n",
    "    #Masks\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool).to(device)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool).to(device)\n",
    "    train_mask[train_indices] = True\n",
    "    test_mask[test_indices] = True\n",
    "    data.train_mask = train_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "    datas[sim_type] = data.to(device)\n",
    "    labels_maps[sim_type] = labels_map\n",
    "\n",
    "#@title Configure GNN Training Parameters { display-mode: \"form\" }\n",
    "#@markdown ## Model Architecture\n",
    "hidden_channels = 32 #@param {type:\"slider\", min:16, max:256, step:16}\n",
    "#@markdown Size of hidden layers in the GNN\n",
    "\n",
    "out_channels = 16 #@param {type:\"slider\", min:8, max:128, step:8}\n",
    "#@markdown Size of output features before classification\n",
    "\n",
    "#@markdown ## Training Parameters\n",
    "learning_rate = 0.002 #@param {type:\"number\"}\n",
    "num_epochs = 1000 #@param {type:\"slider\", min:10, max:10000, step:10}\n",
    "\n",
    "#@markdown ## Visualization Options\n",
    "show_umap_during_training = True #@param {type:\"boolean\"}\n",
    "#@markdown Whether to show UMAP plots during training\n",
    "\n",
    "umap_frequency = 100 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
    "#@markdown Show UMAP visualization every N epochs\n",
    "\n",
    "#@markdown ## Select Simulation\n",
    "simulation_to_train = \"vax_target\" #@param [\"no_vax\", \"vax\", \"vax_target\"]\n",
    "#@markdown Which simulation data to use for training\n",
    "\n",
    "\n",
    "\n",
    "gnn_training_params = {\n",
    "    \"Model Architecture\": {\n",
    "        \"hidden_channels\": hidden_channels,\n",
    "        \"out_channels\": out_channels\n",
    "    },\n",
    "    \"Training\": {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"num_epochs\": num_epochs\n",
    "    },\n",
    "    \"Simulation\": {\n",
    "        \"simulation_to_train\": simulation_to_train\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "with open(os.path.join(cwd,f\"gnn_config_{simulation_to_train}_{selected_model}.json\"), \"w\") as f:\n",
    "    json.dump(gnn_training_params, f, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Get the selected data\n",
    "data = datas[simulation_to_train].to(device)\n",
    "labels_map = labels_maps[simulation_to_train]\n",
    "\n",
    "# Determine input channels from data\n",
    "in_channels = data.x.shape[1]\n",
    "\n",
    "# Reverse the labels map for interpretation\n",
    "reverse_labels_map = {v: k for k, v in labels_map.items()}\n",
    "\n",
    "# Define the GNN model as in the original code\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.linear = nn.Linear(hidden_channels, out_channels)\n",
    "        self.classifier = nn.Linear(out_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.classifier(x)  # Output for the classes\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    # Method to get embeddings for visualization\n",
    "    def get_embeddings(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "# Count number of classes\n",
    "num_classes = len(torch.unique(data.y))\n",
    "\n",
    "# Initialize the model\n",
    "model = GCN(in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            out_channels=out_channels,\n",
    "            num_classes=num_classes).to(device)\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Calculate class weights for imbalanced data\n",
    "class_weights = compute_class_weights(data.y)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "train_aucs = []\n",
    "val_aucs = []\n",
    "\n",
    "print(f\"Training on {simulation_to_train} data with {num_classes} classes\")\n",
    "print(f\"Device: {device}, Model: GCN with {in_channels} input, {hidden_channels} hidden, {out_channels} output channels\")\n",
    "print(f\"Training for {num_epochs} epochs with Adam optimizer (lr={learning_rate})\")\n",
    "print(f\"Class distribution: {np.bincount(data.y.cpu().numpy())}\")\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    out = model(data.x, data.edge_index)\n",
    "\n",
    "    # Compute loss on training nodes\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "\n",
    "        # Get embeddings for visualization\n",
    "        h = model.get_embeddings(data.x, data.edge_index)\n",
    "\n",
    "        # Calculate AUC scores with one-hot encoding\n",
    "        y_true_train = F.one_hot(data.y[data.train_mask], num_classes).float()\n",
    "        y_pred_train = out[data.train_mask]\n",
    "\n",
    "        y_true_val = F.one_hot(data.y[data.test_mask], num_classes).float()\n",
    "        y_pred_val = out[data.test_mask]\n",
    "\n",
    "        # Calculate AUC for each class and average (macro)\n",
    "        train_auc = roc_auc_score(y_true_train.cpu(), y_pred_train.cpu(), multi_class='ovr', average='macro')\n",
    "        val_auc = roc_auc_score(y_true_val.cpu(), y_pred_val.cpu(), multi_class='ovr', average='macro')\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_aucs.append(train_auc)\n",
    "        val_aucs.append(val_auc)\n",
    "\n",
    "    # Print results\n",
    "    if (epoch + 1) % 100 == 0 or epoch == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, Train AUC: {train_auc:.4f}, Val AUC: {val_auc:.4f}')\n",
    "    '''\n",
    "    # Show UMAP visualization if enabled\n",
    "    if show_umap_during_training and (epoch + 1) % umap_frequency == 0:\n",
    "        if epoch > 0:  # Don't clear on first epoch\n",
    "            clear_output(wait=True)\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, Train AUC: {train_auc:.4f}, Val AUC: {val_auc:.4f}')\n",
    "\n",
    "        # Use visualize function\n",
    "        colors = data.y.cpu().numpy()\n",
    "        label_names = [reverse_labels_map.get(i, f\"Class {i}\") for i in range(num_classes)]\n",
    "        auc_dict = {\"train\": train_auc, \"val\": val_auc}\n",
    "        visualize(h, colors, label_names, epoch+1, loss, auc_dict)\n",
    "    '''\n",
    "\n",
    "# Plot final training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_aucs, label='Train')\n",
    "plt.plot(val_aucs, label='Validation')\n",
    "plt.title('AUC Scores')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data.x, data.edge_index)\n",
    "    h = model.get_embeddings(data.x, data.edge_index)\n",
    "\n",
    "    # Print class-wise performance\n",
    "    print(\"\\nClass-wise AUC scores (validation set):\")\n",
    "    y_true_val = F.one_hot(data.y[data.test_mask], num_classes).float().cpu().numpy()\n",
    "    y_pred_val = out[data.test_mask].cpu().numpy()\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        class_name = reverse_labels_map.get(i, f\"Class {i}\")\n",
    "        num_samples = np.sum(y_true_val[:, i])\n",
    "\n",
    "        try:\n",
    "            if num_samples > 0:\n",
    "                class_auc = roc_auc_score(y_true_val[:, i], y_pred_val[:, i])\n",
    "                print(f\"{class_name}: {class_auc:.4f} (samples: {int(num_samples)})\")\n",
    "            else:\n",
    "                print(f\"{class_name}: No samples in validation set\")\n",
    "        except:\n",
    "            print(f\"{class_name}: Not enough samples for AUC calculation\")\n",
    "\n",
    "    # Final UMAP visualization\n",
    "    print(\"\\nFinal model node embeddings:\")\n",
    "    colors = data.y.cpu().numpy()\n",
    "    label_names = [reverse_labels_map.get(i, f\"Class {i}\") for i in range(num_classes)]\n",
    "    auc_dict = {\"train\": train_aucs[-1], \"val\": val_aucs[-1]}\n",
    "    visualize(os.path.join(cwd, f\"final_node_emb_{net}_{simulation_to_train}\"), h, colors, label_names, num_epochs, torch.tensor(train_losses[-1]), auc_dict)\n",
    "\n",
    "# Hide the code\n",
    "display(HTML('''\n",
    "<script>\n",
    "var cell = document.querySelector('.input');\n",
    "if (cell) cell.style.display = 'none';\n",
    "</script>\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 14862,
     "status": "ok",
     "timestamp": 1753174985131,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "09PFFPyflfPv",
    "outputId": "626f884a-0512-4a43-ac74-8a93a17f80fb"
   },
   "outputs": [],
   "source": [
    "#@title Model Evaluation and Visualization { display-mode: \"form\" }\n",
    "#@markdown ## Select what you want to visualize\n",
    "\n",
    "#@markdown ### Model Performance Visualization\n",
    "show_confusion_matrix = True #@param {type:\"boolean\"}\n",
    "show_classification_report = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ### Captum Model Explanations\n",
    "perform_captum_explanations = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown #### Explanation Method\n",
    "explanation_method = \"Integrated Gradients\" #@param [\"Integrated Gradients\", \"Saliency\"]\n",
    "\n",
    "#@markdown #### Target Class to Explain\n",
    "#@markdown Select which class to explain (0-based index)\n",
    "target_class = 0 #@param {type:\"slider\", min:0, max:5, step:1}\n",
    "\n",
    "#@markdown ### Network Visualization\n",
    "visualize_network = True #@param {type:\"boolean\"}\n",
    "show_edge_weights = True #@param {type:\"boolean\"}\n",
    "node_size_factor = 50 #@param {type:\"slider\", min:10, max:100, step:5}\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    # roc_auc_score, # Removed due to persistent error\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import torch\n",
    "from captum.attr import Saliency, IntegratedGradients\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm\n",
    "from collections import defaultdict\n",
    "from IPython.display import display, HTML\n",
    "import itertools\n",
    "\n",
    "# Function to test the model\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    out = model(data.x, data.edge_index)  # Perform a single forward pass\n",
    "    return out\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_cm(filename, cm, classes):\n",
    "    sns.set(style='white')\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    plt.imshow(cm, cmap=\"Blues\")\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.tick_params(labelsize=20, length=0)\n",
    "\n",
    "    ax.set_title('Confusion Matrix', size=24, pad=20)\n",
    "    ax.set_xlabel('Predicted', size=20)\n",
    "    ax.set_ylabel('Target', size=20)\n",
    "\n",
    "    nclasses = len(classes)\n",
    "    ticks = np.arange(0, nclasses, 1)\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\", size=20,\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(cwd, filename), dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "# Function to validate model for multi-class\n",
    "def validate_model_multiclass(y_trues, y_preds, label_names=None):\n",
    "    # Convert raw predictions to class predictions\n",
    "    y_preds_softmax = torch.softmax(y_preds, dim=1)\n",
    "    predicted_classes = torch.argmax(y_preds_softmax, dim=1).cpu().detach().numpy()\n",
    "\n",
    "    y_trues_numpy = y_trues.long().cpu().detach().numpy()\n",
    "    y_preds_numpy = y_preds_softmax.cpu().detach().numpy()\n",
    "\n",
    "    acc = accuracy_score(y_trues_numpy, predicted_classes)\n",
    "    f1 = f1_score(y_trues_numpy, predicted_classes, average=\"macro\")\n",
    "    sensitivity = recall_score(y_trues_numpy, predicted_classes, average=\"macro\")\n",
    "    precision = precision_score(y_trues_numpy, predicted_classes, average=\"macro\")\n",
    "\n",
    "    # roc_auc_score for multiclass with 'ovr' expects 1D y_true and 2D y_score\n",
    "    # Removed due to persistent error:\n",
    "    try:\n",
    "        auc = roc_auc_score(y_trues_numpy, y_preds_numpy, multi_class=\"ovr\", average=\"macro\")\n",
    "    except ValueError as e:\n",
    "         print(f\"Could not compute ROC AUC: {e}\")\n",
    "         auc = np.nan # Assign NaN if calculation fails\n",
    "\n",
    "\n",
    "    if label_names is None:\n",
    "        label_names = [f\"Class {i}\" for i in range(np.max(y_trues_numpy) + 1)]\n",
    "\n",
    "    # Show classification report if requested\n",
    "    if show_classification_report:\n",
    "        cr = classification_report(y_trues_numpy, predicted_classes, target_names=label_names)\n",
    "        print(\"Classification Report:\")\n",
    "        print(cr)\n",
    "        with open(os.path.join(cwd, f\"class_report{net}_{simulation_to_train}.json\"), \"w\") as f:\n",
    "            f.write(\"Classification Report:\\n\")\n",
    "            f.write(cr)\n",
    "\n",
    "\n",
    "    # Show confusion matrix if requested\n",
    "    if show_confusion_matrix:\n",
    "        cm = confusion_matrix(y_trues_numpy, predicted_classes)\n",
    "        plot_cm(f\"confusion_matrix_{net}_{simulation_to_train}.png\",cm, label_names)\n",
    "\n",
    "    # Generate summary string\n",
    "    summary = (\n",
    "        f\"Accuracy: {acc:.4f}\\n\"\n",
    "        f\"Macro F1 Score: {f1:.4f}\\n\"\n",
    "        f\"Macro Sensitivity (Recall): {sensitivity:.4f}\\n\"\n",
    "        f\"Macro Precision: {precision:.4f}\\n\"\n",
    "        #f\"ROC AUC (macro): {auc:.4f}\\n\" # Removed from summary\n",
    "    )\n",
    "\n",
    "    print(summary)\n",
    "    # Return metrics excluding AUC for now\n",
    "    return [acc, f1, sensitivity, precision], summary\n",
    "\n",
    "# Forward function for Captum explanations\n",
    "def model_forward(edge_mask, data):\n",
    "    out = model.forward(data.x, data.edge_index, edge_mask)\n",
    "    return out\n",
    "\n",
    "# Function to explain model predictions\n",
    "def explain(method, data, target=0):\n",
    "    input_mask = torch.ones(data.edge_index.shape[1]).requires_grad_(True).to(device)\n",
    "\n",
    "    if method == 'ig' or method == 'Integrated Gradients':\n",
    "        ig = IntegratedGradients(model_forward)\n",
    "        mask = ig.attribute(input_mask, target=target,\n",
    "                            additional_forward_args=(data,),\n",
    "                            internal_batch_size=data.edge_index.shape[1])\n",
    "    elif method == 'saliency' or method == 'Saliency':\n",
    "        saliency = Saliency(model_forward)\n",
    "        mask = saliency.attribute(input_mask, target=target,\n",
    "                                  additional_forward_args=(data,))\n",
    "    else:\n",
    "        raise Exception('Unknown explanation method')\n",
    "\n",
    "    edge_mask = np.abs(mask.cpu().detach().numpy())\n",
    "    if edge_mask.max() > 0:  # avoid division by zero\n",
    "        edge_mask = edge_mask / edge_mask.max()\n",
    "    return edge_mask\n",
    "\n",
    "# Function to aggregate edge directions\n",
    "def aggregate_edge_directions(edge_mask, data):\n",
    "    edge_mask_dict = defaultdict(float)\n",
    "    for val, u, v in list(zip(edge_mask, *data.edge_index)):\n",
    "        u, v = u.item(), v.item()\n",
    "        if u > v:\n",
    "            u, v = v, u\n",
    "        edge_mask_dict[(u, v)] += val\n",
    "    return edge_mask_dict\n",
    "\n",
    "# Function to draw network with explanations\n",
    "def visualize_network_with_explanations(data, G, method, edge_mask_dict, title):\n",
    "    # Normalize weights for visualization\n",
    "    if edge_mask_dict:\n",
    "        max_weight = max(edge_mask_dict.values())\n",
    "        normalized_weights = {edge: weight / max_weight for edge, weight in edge_mask_dict.items()}\n",
    "    else:\n",
    "        normalized_weights = {}\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    plt.title(title, fontsize=16)\n",
    "\n",
    "    # Use a layout that ensures good separation between nodes\n",
    "    pos = nx.spring_layout(G, seed=42, k=2/np.sqrt(G.number_of_nodes()))\n",
    "\n",
    "    # Draw edges with thickness proportional to weights if show_edge_weights is True\n",
    "    if show_edge_weights and normalized_weights:\n",
    "        edges, weights = zip(*normalized_weights.items())\n",
    "        nx.draw_networkx_edges(G, pos,\n",
    "                              edgelist=edges,\n",
    "                              width=[5 * w for w in weights],\n",
    "                              edge_color=weights,\n",
    "                              edge_cmap=cm.viridis)\n",
    "    else:\n",
    "        nx.draw_networkx_edges(G, pos, alpha=0.3)\n",
    "\n",
    "    # Draw nodes with sizes proportional to their degree\n",
    "    node_sizes = [node_size_factor + node_size_factor * G.degree(n) / max(dict(G.degree()).values()) for n in G.nodes()]\n",
    "\n",
    "    # Get node colors from class labels\n",
    "    node_colors = data.y.cpu().detach().numpy()\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos,\n",
    "                          node_size=node_sizes,\n",
    "                          node_color=node_colors,\n",
    "                          cmap=cm.tab20)\n",
    "\n",
    "    # Add labels to nodes if there aren't too many\n",
    "    if len(G.nodes()) < 100:\n",
    "        nx.draw_networkx_labels(G, pos, font_size=8, font_color='black')\n",
    "\n",
    "    # Add a color bar for edge weights if showing weights\n",
    "    if show_edge_weights and normalized_weights:\n",
    "        plt.colorbar(plt.cm.ScalarMappable(cmap=cm.viridis),\n",
    "                    label=\"Normalized Edge Weights\",\n",
    "                    shrink=0.8, ax=ax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(os.path.join(cwd, f\"xai{net}_{method}.png\"), dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "# Get data for evaluation\n",
    "data = datas[simulation_to_train].to(device)\n",
    "model.to(device)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = test(data)\n",
    "y_test = data.y\n",
    "\n",
    "# Get label names\n",
    "try:\n",
    "    label_names = list(labels_maps[simulation_to_train].keys())\n",
    "    print(f\"Classes: {label_names}\")\n",
    "except:\n",
    "    label_names = [f\"Class {i}\" for i in range(len(torch.unique(y_test)))]\n",
    "    print(f\"Using default class names: {label_names}\")\n",
    "\n",
    "# Evaluate model performance\n",
    "# Pass y_test (1D tensor) and y_pred (2D tensor of probabilities)\n",
    "metrics, _ = validate_model_multiclass(y_test, y_pred, label_names=label_names)\n",
    "\n",
    "# Perform Captum explanations if requested\n",
    "if perform_captum_explanations:\n",
    "    print(f\"\\nGenerating {explanation_method} explanations for class: {label_names[target_class]}\")\n",
    "\n",
    "    # Check that target class is valid\n",
    "    if target_class >= len(label_names):\n",
    "        print(f\"Warning: Target class index {target_class} is out of bounds. Using class 0 instead.\")\n",
    "        target_class = 0\n",
    "\n",
    "    # Get method name in format expected by explain function\n",
    "    method_name = 'ig' if explanation_method == \"Integrated Gradients\" else 'saliency'\n",
    "\n",
    "    # Compute masks and aggregate\n",
    "    edge_mask = explain(method_name, data, target=target_class)\n",
    "    edge_mask_dict = aggregate_edge_directions(edge_mask, data)\n",
    "\n",
    "    # Visualize network with explanations if requested\n",
    "    if visualize_network:\n",
    "        try:\n",
    "            G = sim.G  # Try to get the graph from simulation\n",
    "        except:\n",
    "            # Create a networkx graph from the edge_index\n",
    "            G = nx.Graph()\n",
    "            edge_index = data.edge_index.cpu().numpy()\n",
    "            for i in range(edge_index.shape[1]):\n",
    "                G.add_edge(edge_index[0, i], edge_index[1, i])\n",
    "\n",
    "        visualize_network_with_explanations(\n",
    "            data,\n",
    "            G, method_name,\n",
    "            edge_mask_dict,\n",
    "            f\"{explanation_method} Explanations for Class: {label_names[target_class]}\"\n",
    "        )\n",
    "\n",
    "# Hide the code\n",
    "display(HTML('''\n",
    "<script>\n",
    "var cell = document.querySelector('.input');\n",
    "if (cell) cell.style.display = 'none';\n",
    "</script>\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1753174985146,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "fhFAlQZ1MuEb",
    "outputId": "744523ad-b556-4cb3-b017-561aa0ceec3a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "\n",
    "#@title Node-level state probabilities { display-mode: \"form\" }\n",
    "#@markdown ## Select the node you want to predict probabilities\n",
    "idx = 29 #@param {type:\"slider\", min:0, max:100, step:1}\n",
    "\n",
    "pred = y_pred[idx].cpu().detach().numpy()\n",
    "df_pred = pd.DataFrame(columns = labels_map)\n",
    "df_pred.loc[idx] = list(pred)\n",
    "df_pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4253,
     "status": "ok",
     "timestamp": 1753174989400,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "pLDTbqZiU9eg",
    "outputId": "835d3d9f-fe75-4b55-f842-bf9c75b4987a"
   },
   "outputs": [],
   "source": [
    "#@title XAI experiments: remove most influent edges{ display-mode: \"form\" }\n",
    "\n",
    "import pandas as pd\n",
    "# Configuration parameters\n",
    "edge_removal_percentage = 35 #@param {type:\"slider\", min:5, max:80, step:5}\n",
    "#@markdown Percentage of edges to remove\n",
    "intervention_steps = steps  # Same step number of orginal simulation\n",
    "\n",
    "# --- Step 1: Edge importance with Captum ---\n",
    "print(f\"Computation of edge importance with {explanation_method}for target class '{target_class}'\")\n",
    "edge_mask = explain('saliency' if explanation_method == \"Saliency\" else 'ig', data, target=target_class)\n",
    "edge_mask_dict = aggregate_edge_directions(edge_mask, data)\n",
    "\n",
    "# --- Step 2: Rimozione dei top-K% archi più influenti ---\n",
    "sorted_edges = sorted(edge_mask_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "num_edges_to_remove = int(len(sorted_edges) * (edge_removal_percentage / 100))\n",
    "edges_to_remove = [e for e, _ in sorted_edges[:num_edges_to_remove]]\n",
    "\n",
    "G_modified = sim.G.copy()\n",
    "G_modified.remove_edges_from(edges_to_remove)\n",
    "print(f\"{len(edges_to_remove)} most influential edges removed (top {edge_removal_percentage}%)\")\n",
    "\n",
    "\n",
    "vaccination_type = str()\n",
    "if simulation_to_train == \"vax_target\":\n",
    "    vaccination_type = \"betweenness\"\n",
    "elif simulation_to_train == \"vax\":\n",
    "    vaccination_type = \"random\"\n",
    "\n",
    "# --- Step 3: Simulation with modified graph ---\n",
    "sim_explained = Simulation(\n",
    "    G_modified,\n",
    "    initial_state,\n",
    "    state_transition,\n",
    "    sim_params[simulation_to_train],   #SIRVD parameters\n",
    "    vaccination_type = vaccination_type,\n",
    "    name=\"SIRVD - XAI Edge Removal\"\n",
    ")\n",
    "sim_explained.run(intervention_steps)\n",
    "\n",
    "# --- Step 4: Adding the new simulation to the dictionary for comparison ---\n",
    "sims[\"explainability\"] = sim_explained\n",
    "\n",
    "strategy_labels = {\n",
    "    \"no_vax\": \"No Vaccination\",\n",
    "    \"vax\": \"Random Vaccination\",\n",
    "    \"vax_target\": \"Targeted Vaccination\",\n",
    "    \"explainability\": f\"XAI Edge Removal ({edge_removal_percentage}%)\"\n",
    "}\n",
    "\n",
    "# --- Step 5: Show the results ---\n",
    "\n",
    "tracked_states = [\"Ih\", \"Dh\"]\n",
    "for idx, state in enumerate(tracked_states):\n",
    "    single_fig = plt.figure()\n",
    "    single_ax = single_fig.add_subplot(111)\n",
    "\n",
    "    for key in strategy_labels:\n",
    "        sim = sims[key]\n",
    "        proportions = []\n",
    "        for t in range(intervention_steps):\n",
    "            state_count = Counter(sim.state(t).values())\n",
    "            total = sum(state_count.values())\n",
    "            proportions.append(state_count.get(state, 0) / total)\n",
    "        single_ax.plot(proportions, label=strategy_labels[key])\n",
    "\n",
    "    single_ax.set_title(f\"{state} over time\")\n",
    "    single_ax.set_xlabel(\"Step\")\n",
    "    single_ax.set_ylabel(\"Proportion\")\n",
    "    single_ax.legend()\n",
    "    single_ax.grid(alpha=0.3)\n",
    "\n",
    "    save_path = os.path.join(cwd, f\"{state}_edge removal_({edge_removal_percentage}).png\")\n",
    "    single_fig.savefig(save_path, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Step 6: Summary table ---\n",
    "summary_data = []\n",
    "for key in strategy_labels:\n",
    "    sim = sims[key]\n",
    "    infections = []\n",
    "    deaths = []\n",
    "    for t in range(intervention_steps):\n",
    "        state_count = Counter(sim.state(t).values())\n",
    "        total = sum(state_count.values())\n",
    "        infections.append(state_count.get(\"Ih\", 0) / total)\n",
    "        deaths.append(state_count.get(\"Dh\", 0) / total)\n",
    "    peak_infected = max(infections)\n",
    "    total_dead = deaths[-1]\n",
    "    duration = next((t for t, val in enumerate(infections[::-1]) if val > 0), 0)\n",
    "    duration = intervention_steps - duration if duration > 0 else intervention_steps\n",
    "    summary_data.append([\n",
    "        strategy_labels[key],\n",
    "        f\"{peak_infected:.2%}\",\n",
    "        f\"{total_dead:.2%}\",\n",
    "        duration\n",
    "    ])\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data, columns=[\"Strategy\", \"Peak Infected\", \"Total Dead\", \"Duration\"])\n",
    "summary_records = df_summary.to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "final_json = {\n",
    "    \"summary\": summary_records,\n",
    "    \"removed edges\": len(edges_to_remove)\n",
    "}\n",
    "\n",
    "with open(os.path.join(cwd, f\"sirvd_summary_edge_rem_{edge_removal_percentage}.json\"), \"w\") as f:\n",
    "    json.dump(final_json, f, indent=4)\n",
    "\n",
    "\n",
    "#df_summary = pd.DataFrame(summary_data, columns=[\"Strategy\", \"Peak Infected\", \"Total Dead\", \"Duration\"])\n",
    "display(HTML(\"<h3>Summary: Explainability-Guided Intervention on SIRVD</h3>\"))\n",
    "display(df_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4034,
     "status": "ok",
     "timestamp": 1753175001799,
     "user": {
      "displayName": "ANNAMARIA DEFILIPPO",
      "userId": "16338426362459885029"
     },
     "user_tz": -120
    },
    "id": "QoG9OJKXHXEZ",
    "outputId": "8ef70f84-e2bf-4828-ff13-930af9143b1e"
   },
   "outputs": [],
   "source": [
    "#@title XAI experiments: Targeted Vaccination { display-mode: \"form\" }\n",
    "# Configuration parameters\n",
    "top_k_percent_nodes = 50 #@param {type:\"slider\", min:5, max:80, step:5}\n",
    "#@markdown ####Top K% most influential nodes\n",
    "\n",
    "# --- Step 1: Compute super-spreader with XAI  ---\n",
    "print(f\"→ Compute super-spreader with {explanation_method}...\")\n",
    "\n",
    "if 'edge_mask_dict' not in globals():\n",
    "    edge_mask = explain('saliency' if explanation_method == \"Saliency\" else 'ig', data, target=target_class)\n",
    "    edge_mask_dict = aggregate_edge_directions(edge_mask, data)\n",
    "\n",
    "#Compute node scores with edge contributions\n",
    "from collections import defaultdict\n",
    "node_scores = defaultdict(float)\n",
    "for (u, v), score in edge_mask_dict.items():\n",
    "    node_scores[u] += score\n",
    "    node_scores[v] += score\n",
    "\n",
    "#Selecting top K% most influential nodes\n",
    "num_nodes = len(sim.G.nodes)\n",
    "#top_k_percent_nodes = 10\n",
    "top_k = int(num_nodes * top_k_percent_nodes / 100)\n",
    "top_nodes = sorted(node_scores, key=node_scores.get, reverse=True)[:top_k]\n",
    "\n",
    "print(f\"→ Vaccination of top {top_k_percent_nodes}% most influential nodes({top_k} nodes)\")\n",
    "\n",
    "# --- Step 2: Intial state with targeted vaccintation of super-spreader ---\n",
    "def targeted_vaccination_initial_state(G, vaccinated_nodes):\n",
    "    state = {node: 'Sh' for node in G.nodes}\n",
    "    for node in vaccinated_nodes:\n",
    "        state[node] = 'Vh'\n",
    "    #Patient zero\n",
    "    susceptible_nodes = [n for n in G.nodes if state[n] == 'Sh']\n",
    "    if susceptible_nodes:\n",
    "        paziente_zero = random.choice(susceptible_nodes)\n",
    "        state[paziente_zero] = 'Ih'\n",
    "    nx.set_node_attributes(G, state, 'state')\n",
    "    return state\n",
    "\n",
    "\n",
    "vaccination_type = \"random\"\n",
    "if simulation_to_train == \"vax_target\":\n",
    "    vaccination_type = \"betweenness\"\n",
    "\n",
    "# --- Step 3: Simulation with targeted vaccination of super-spreader ---\n",
    "sim_vax_explained = Simulation(\n",
    "    sim.G,\n",
    "    lambda G: targeted_vaccination_initial_state(G, top_nodes),\n",
    "    state_transition,\n",
    "    params_vax_target,\n",
    "    vaccination_type= vaccination_type,\n",
    "    name=\"Explainability-Guided Vaccination\"\n",
    ")\n",
    "\n",
    "sim_vax_explained.run(steps)\n",
    "\n",
    "# --- Step 4: Updating dictionaries and plots ---\n",
    "\n",
    "sims[\"vax_explained\"] = sim_vax_explained\n",
    "strategy_labels[\"vax_explained\"] = f\"XAI Targeted Vaccination ({top_k_percent_nodes}%)\"\n",
    "\n",
    "for state in tracked_states:\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "    for key in [\"no_vax\", \"vax\", \"vax_target\", \"vax_explained\"]:\n",
    "        sim = sims[key]\n",
    "        proportions = []\n",
    "        for t in range(steps):\n",
    "            state_count = Counter(sim.state(t).values())\n",
    "            total = sum(state_count.values())\n",
    "            proportions.append(state_count.get(state, 0) / total)\n",
    "        ax.plot(proportions, label=strategy_labels[key])\n",
    "\n",
    "    ax.set_title(f\"{state} over time\")\n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.set_ylabel(\"Proportion\")\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "\n",
    "    save_path = os.path.join(cwd, f\"{state}_xai_vaccination_{top_k_percent_nodes}.png\")\n",
    "    fig.savefig(save_path, dpi=600)\n",
    "    plt.show(fig)\n",
    "\n",
    "\n",
    "# --- Step 5: Summary table ---\n",
    "summary_data_vax = []\n",
    "for key in [\"no_vax\", \"vax\", \"vax_target\", \"vax_explained\"]:\n",
    "    sim = sims[key]\n",
    "    infections = []\n",
    "    deaths = []\n",
    "    for t in range(steps):\n",
    "        state_count = Counter(sim.state(t).values())\n",
    "        total = sum(state_count.values())\n",
    "        infections.append(state_count.get(\"Ih\", 0) / total)\n",
    "        deaths.append(state_count.get(\"Dh\", 0) / total)\n",
    "    peak_infected = max(infections)\n",
    "    total_dead = deaths[-1]\n",
    "    duration = next((t for t, val in enumerate(infections[::-1]) if val > 0), 0)\n",
    "    duration = steps - duration if duration > 0 else steps\n",
    "    summary_data_vax.append([\n",
    "        strategy_labels[key],\n",
    "        f\"{peak_infected:.2%}\",\n",
    "        f\"{total_dead:.2%}\",\n",
    "        duration\n",
    "    ])\n",
    "\n",
    "df_vax_summary = pd.DataFrame(summary_data_vax, columns=[\"Strategy\", \"Peak Infected\", \"Total Dead\", \"Duration\"])\n",
    "summary_vax_records = df_vax_summary.to_dict(orient=\"records\")\n",
    "\n",
    "final_json_vax = {\n",
    "    \"summary\": summary_vax_records,\n",
    "    \"vaccinated\": top_k\n",
    "}\n",
    "\n",
    "with open(os.path.join(cwd, f\"sirvd_summary_targeted_{top_k_percent_nodes}.json\"), \"w\") as f:\n",
    "    json.dump(final_json_vax, f, indent=4)\n",
    "\n",
    "display(HTML(\"<h3>Summary: Explainability-Guided Targeted Vaccination</h3>\"))\n",
    "display(df_vax_summary)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "176MOUCGjBXPAx9bub7PSNCt-AK1oXAzL",
     "timestamp": 1752130105330
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
